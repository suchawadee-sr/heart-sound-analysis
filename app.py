import streamlit as st
import gdown
import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
import librosa.display
import soundfile as sf
from scipy.signal import butter, filtfilt
from tensorflow.keras.models import load_model

# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹ƒà¸«à¹‰ Streamlit à¸£à¸­à¸‡à¸£à¸±à¸š layout à¸à¸§à¹‰à¸²à¸‡
st.set_page_config(page_title="Heartbeat Health", layout="wide")

# ğŸ¨ **à¸•à¸à¹à¸•à¹ˆà¸‡ Header**
header_html = """
    <div style="
        background: linear-gradient(to bottom, #FF6B6B, #FFA07A);
        padding: 15px 20px;
        text-align: left;
        border-radius: 10px;">
        <h1 style="color: white; font-size: 28px; display: inline;">â¤ï¸ heartbeat health</h1>
        <span style="float: right; font-size: 28px;">ğŸ–¤ ğŸ¤ â¤ï¸</span>
    </div>
"""
st.markdown(header_html, unsafe_allow_html=True)

# ğŸ¯ **à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥**
GDRIVE_FILE_ID = "13oUZjw0OTeOoxbk5-CZHsuDonY2oquPO"
model_path = "model_heartbeat.h5"
if not os.path.exists(model_path):
    st.write("ğŸ“¥ Downloading model from Google Drive...")
    url = f"https://drive.google.com/uc?id={GDRIVE_FILE_ID}"
    gdown.download(url, model_path, quiet=False)

st.write("âœ… Loading model...")
model = load_model(model_path)
st.write("âœ… Model loaded successfully!")

# ğŸ¯ **Band-pass Filter (20Hz - 200Hz)**
def bandpass_filter(y, sr, lowcut=20.0, highcut=200.0, order=4):
    nyq = 0.5 * sr
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype="band")
    return filtfilt(b, a, y)

# ğŸ¯ **Spectrogram Plot**
def plot_spectrogram(y, sr, title="Spectrogram"):
    fig, ax = plt.subplots(figsize=(6, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis="time", y_axis="log", cmap="magma")
    plt.colorbar(format="%+2.0f dB")
    plt.title(title)
    return fig

# ğŸ¯ **à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹€à¸ªà¸µà¸¢à¸‡**
def preprocess_audio(file_path, sr=4000, n_mels=128, max_frames=128):
    try:
        y, sr = librosa.load(file_path, sr=sr)
        y_filtered = bandpass_filter(y, sr)
        mel_spec = librosa.feature.melspectrogram(y=y_filtered, sr=sr, n_mels=n_mels)
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

        if mel_spec_db.shape[1] < max_frames:
            pad_width = max_frames - mel_spec_db.shape[1]
            mel_spec_db = np.pad(mel_spec_db, pad_width=((0, 0), (0, pad_width)), mode="constant")
        else:
            mel_spec_db = mel_spec_db[:, :max_frames]

        return mel_spec_db.reshape(1, 128, 128, 1), y, y_filtered, sr
    except Exception as e:
        st.error(f"âŒ Error processing audio: {e}")
        return None, None, None, None

# ğŸ¯ **à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡**
st.markdown("ğŸ“‚ **à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸«à¸±à¸§à¹ƒà¸ˆ (.wav)**")
uploaded_file = st.file_uploader("Drag and drop file here", type=["wav"])

if uploaded_file is not None:
    file_path = "uploaded_heart_sound.wav"
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    preprocessed_audio, y_raw, y_filtered, sr = preprocess_audio(file_path)

    if preprocessed_audio is not None:
        # ğŸ¯ **à¹à¸šà¹ˆà¸‡à¸«à¸™à¹‰à¸²à¸ˆà¸­ 2 à¸à¸±à¹ˆà¸‡**
        col1, col2 = st.columns(2)

        # **à¸à¸±à¹ˆà¸‡à¸‹à¹‰à¸²à¸¢**: à¹à¸ªà¸”à¸‡ Waveform à¸à¹ˆà¸­à¸™à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡
        with col1:
            st.markdown("ğŸµ **Waveform à¸à¹ˆà¸­à¸™à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡**")
            fig, ax = plt.subplots(figsize=(6, 3))
            librosa.display.waveshow(y_raw, sr=sr, color="gray")
            plt.title("Raw Heart Sound")
            plt.xlabel("Time (s)")
            plt.ylabel("Amplitude")
            st.pyplot(fig)

        # **à¸à¸±à¹ˆà¸‡à¸‚à¸§à¸²**: à¹à¸ªà¸”à¸‡ Waveform à¸«à¸¥à¸±à¸‡à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡
        with col2:
            st.markdown("ğŸ¶ **Waveform à¸«à¸¥à¸±à¸‡à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡**")
            fig, ax = plt.subplots(figsize=(6, 3))
            librosa.display.waveshow(y_filtered, sr=sr, color="blue")
            plt.title("Filtered Heart Sound")
            plt.xlabel("Time (s)")
            plt.ylabel("Amplitude")
            st.pyplot(fig)

        # ğŸ¯ **Spectrogram à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š**
        st.markdown("ğŸ¨ **Spectrogram à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¹ˆà¸­à¸™à¹à¸¥à¸°à¸«à¸¥à¸±à¸‡à¸à¸²à¸£à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡:**")
        col3, col4 = st.columns(2)

        with col3:
            st.markdown("ğŸ¼ **à¸à¹ˆà¸­à¸™à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡**")
            st.pyplot(plot_spectrogram(y_raw, sr, title="Raw Spectrogram"))

        with col4:
            st.markdown("ğŸ¼ **à¸«à¸¥à¸±à¸‡à¸à¸£à¸­à¸‡à¹€à¸ªà¸µà¸¢à¸‡**")
            st.pyplot(plot_spectrogram(y_filtered, sr, title="Filtered Spectrogram"))

        # ğŸ¯ **à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸”à¹‰à¸§à¸¢ AI**
        prediction = model.predict(preprocessed_audio)
        predicted_class = np.argmax(prediction)
        confidence = prediction[0][predicted_class]

        classes = ["â¤ï¸ Healthy", "ğŸ’” Unhealthy"]
        st.markdown(f"## ğŸ” **à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ:** {classes[predicted_class]} (à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ: {confidence:.2f})")
